{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "OT_LOGS_DIR = Path(\"/lustre/groups/eml/projects/sroschmann/ot_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params(params_path):\n",
    "    params = {}\n",
    "    if not params_path.exists():\n",
    "        return params\n",
    "\n",
    "    try:\n",
    "        with open(params_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if \":\" in line:\n",
    "                    key, val = line.split(\":\", 1)\n",
    "                elif \"=\" in line:\n",
    "                    key, val = line.split(\"=\", 1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                params[key.strip()] = val.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {params_path}: {e}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_flatten_metrics(json_path, prefix):\n",
    "    metrics = {}\n",
    "    if not json_path.exists():\n",
    "        return metrics\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            epoch_best = data.get(\"epoch_best\", {})\n",
    "\n",
    "            if isinstance(epoch_best, dict):\n",
    "                for key, value in epoch_best.items():\n",
    "                    col_name = f\"{prefix}_{key}\"\n",
    "                    metrics[col_name] = value\n",
    "            else:\n",
    "                raise ValueError(\"epoch_best is not a dictionary\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Issue parsing {json_path}: {e}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_dataframe(base_dir):\n",
    "    data_rows = []\n",
    "    print(f\"Scanning directory: {base_dir} ...\")\n",
    "\n",
    "    # Iterate over all subdirectories in ot_logs\n",
    "    for exp_dir in base_dir.iterdir():\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        row = {\"experiment_id\": exp_dir.name, \"full_path\": str(exp_dir)}\n",
    "\n",
    "        # Parse Params (Metadata)\n",
    "        params_path = exp_dir / \"params.txt\"\n",
    "        row.update(parse_params(params_path))\n",
    "\n",
    "        # Load COCO Metrics\n",
    "        coco_path = exp_dir / \"results\" / \"COCO\" / \"alignment_probing.json\"\n",
    "        coco_metrics = load_and_flatten_metrics(coco_path, prefix=\"coco\")\n",
    "        row.update(coco_metrics)\n",
    "\n",
    "        # Load ImageNet Metrics\n",
    "        imagenet_path = exp_dir / \"results\" / \"imagenetv1\" / \"alignment_probing.json\"\n",
    "        imagenet_metrics = load_and_flatten_metrics(imagenet_path, prefix=\"imagenet\")\n",
    "        row.update(imagenet_metrics)\n",
    "\n",
    "        data_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35524d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_and_dataset(path_str):\n",
    "    if not isinstance(path_str, str):\n",
    "        return None, None\n",
    "    \n",
    "    # Clean artifacts: remove brackets, quotes, commas\n",
    "    cleaned_str = path_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\",\", \" \")\n",
    "    \n",
    "    # Split into individual paths\n",
    "    paths = cleaned_str.split()\n",
    "    \n",
    "    models = []\n",
    "    datasets = []\n",
    "    \n",
    "    for p in paths:\n",
    "        parts = p.strip(\"/\").split(\"/\")\n",
    "        if len(parts) >= 2:\n",
    "            models.append(parts[-2]) \n",
    "            datasets.append(parts[-1])\n",
    "            \n",
    "    if not models:\n",
    "        return None, None\n",
    "        \n",
    "    final_model = models[0]\n",
    "    final_dataset = \" + \".join(datasets)\n",
    "    \n",
    "    return final_model, final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = build_results_dataframe(OT_LOGS_DIR)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No experiments found.\")\n",
    "else:\n",
    "    # Define base columns (metrics + params)\n",
    "    param_columns = [\n",
    "        \"seed\", \"linear-type\", \"width-factor\", \"logit_scale\", \"logit_bias\",\n",
    "        \"semisupervised\", \"n_supervised_pairs\", \"batch-size-supervised\",\n",
    "        \"n_unsupervised_image\", \"n_unsupervised_text\", \"anchor_lam_x\",\n",
    "        \"anchor_lam_y\", \"alpha_semisupervised_sail\", \"alpha_semisupervised_ot\",\n",
    "        \"epsilon_sinkhorn_shared\", \"n_iters_sinkhorn_shared\",\n",
    "        \"epsilon_sinkhorn_anchor\", \"n_iters_sinkhorn_anchor\",\n",
    "        \"unsupervised_index_mode\",\n",
    "    ]\n",
    "\n",
    "    key_metrics = [\n",
    "        \"experiment_id\", \"coco_T2I R@1\", \"coco_T2I R@5\",\n",
    "        \"coco_I2T R@1\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\",\n",
    "    ]\n",
    "\n",
    "    # Extract Models and Datasets for ALL embedding columns\n",
    "    all_embedding_cols = [\n",
    "        \"supervised_image_embedding\", \"supervised_text_embedding\",\n",
    "        \"unsupervised_image_embedding\", \"unsupervised_text_embedding\",\n",
    "        \"val_image_embedding\", \"val_text_embedding\"\n",
    "    ]\n",
    "\n",
    "    dataset_cols = []\n",
    "\n",
    "    for col in all_embedding_cols:\n",
    "        if col in df.columns:\n",
    "            base_name = col.replace(\"_embedding\", \"\")\n",
    "            extracted = df[col].apply(extract_model_and_dataset)\n",
    "            \n",
    "            df[f\"{base_name}_model\"] = extracted.apply(lambda x: x[0])\n",
    "            df[f\"{base_name}\"] = extracted.apply(lambda x: x[1])\n",
    "            dataset_cols.append(base_name)\n",
    "            \n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Assert and merge image models\n",
    "    if \"supervised_image_model\" in df.columns and \"unsupervised_image_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_image_model\"] != df[\"unsupervised_image_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_image_model != unsupervised_image_model\")\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_image_model\", \"unsupervised_image_model\"]])\n",
    "        \n",
    "        df[\"image_model\"] = df[\"supervised_image_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_image_model\", \"unsupervised_image_model\"]\n",
    "        if \"val_image_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_image_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # Assert and merge text models\n",
    "    if \"supervised_text_model\" in df.columns and \"unsupervised_text_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_text_model\"] != df[\"unsupervised_text_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_text_model != unsupervised_text_model\")\n",
    "            print(mismatches['experiment_id'])\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_text_model\", \"unsupervised_text_model\"]])\n",
    "\n",
    "        df[\"text_model\"] = df[\"supervised_text_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_text_model\", \"unsupervised_text_model\"]\n",
    "        if \"val_text_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_text_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    dataset_cols.sort()\n",
    "    model_cols = [\"image_model\", \"text_model\"]\n",
    "    \n",
    "    final_cols = key_metrics + model_cols + dataset_cols + param_columns\n",
    "    final_cols = [c for c in final_cols if c in df.columns]\n",
    "\n",
    "    df = df[final_cols]\n",
    "\n",
    "    # Sort by main metric\n",
    "    if \"coco_T2I R@1\" in df.columns:\n",
    "        df = df.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "\n",
    "    print(f\"\\nLoaded {len(df)} experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
