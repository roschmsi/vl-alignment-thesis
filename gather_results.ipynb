{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77f13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7946877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "OT_LOGS_DIR = Path(\"/lustre/groups/eml/projects/sroschmann/ot_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b80607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params(params_path):\n",
    "    params = {}\n",
    "    if not params_path.exists():\n",
    "        return params\n",
    "\n",
    "    try:\n",
    "        with open(params_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if \":\" in line:\n",
    "                    key, val = line.split(\":\", 1)\n",
    "                elif \"=\" in line:\n",
    "                    key, val = line.split(\"=\", 1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                params[key.strip()] = val.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {params_path}: {e}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9babf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_flatten_metrics(json_path, prefix):\n",
    "    metrics = {}\n",
    "    if not json_path.exists():\n",
    "        return metrics\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            epoch_best = data.get(\"epoch_best\", {})\n",
    "\n",
    "            if isinstance(epoch_best, dict):\n",
    "                for key, value in epoch_best.items():\n",
    "                    col_name = f\"{prefix}_{key}\"\n",
    "                    metrics[col_name] = value\n",
    "            else:\n",
    "                raise ValueError(\"epoch_best is not a dictionary\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Issue parsing {json_path}: {e}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd952b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_dataframe(base_dir):\n",
    "    data_rows = []\n",
    "    print(f\"Scanning directory: {base_dir} ...\")\n",
    "\n",
    "    # Iterate over all subdirectories in ot_logs\n",
    "    for exp_dir in base_dir.iterdir():\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        row = {\"experiment_id\": exp_dir.name, \"full_path\": str(exp_dir)}\n",
    "\n",
    "        # Parse Params (Metadata)\n",
    "        params_path = exp_dir / \"params.txt\"\n",
    "        row.update(parse_params(params_path))\n",
    "\n",
    "        # Load COCO Metrics\n",
    "        coco_path = exp_dir / \"results\" / \"COCO\" / \"alignment_probing.json\"\n",
    "        coco_metrics = load_and_flatten_metrics(coco_path, prefix=\"coco\")\n",
    "        row.update(coco_metrics)\n",
    "\n",
    "        # Load ImageNet Metrics\n",
    "        imagenet_path = exp_dir / \"results\" / \"imagenetv1\" / \"alignment_probing.json\"\n",
    "        imagenet_metrics = load_and_flatten_metrics(imagenet_path, prefix=\"imagenet\")\n",
    "        row.update(imagenet_metrics)\n",
    "\n",
    "        data_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35524d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_and_dataset(path_str):\n",
    "    if not isinstance(path_str, str):\n",
    "        return None, None\n",
    "    \n",
    "    # Clean artifacts: remove brackets, quotes, commas\n",
    "    cleaned_str = path_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\",\", \" \")\n",
    "    \n",
    "    # Split into individual paths\n",
    "    paths = cleaned_str.split()\n",
    "    \n",
    "    models = []\n",
    "    datasets = []\n",
    "    \n",
    "    for p in paths:\n",
    "        parts = p.strip(\"/\").split(\"/\")\n",
    "        if len(parts) >= 2:\n",
    "            models.append(parts[-2]) \n",
    "            datasets.append(parts[-1])\n",
    "            \n",
    "    if not models:\n",
    "        return None, None\n",
    "        \n",
    "    final_model = models[0]\n",
    "    final_dataset = \" + \".join(datasets)\n",
    "    \n",
    "    return final_model, final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f5910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: /lustre/groups/eml/projects/sroschmann/ot_logs ...\n",
      "\n",
      "Loaded 3 experiments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = build_results_dataframe(OT_LOGS_DIR)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No experiments found.\")\n",
    "else:\n",
    "    # Define base columns (metrics + params)\n",
    "    param_columns = [\n",
    "        \"seed\", \"linear-type\", \"width-factor\", \"logit_scale\", \"logit_bias\",\n",
    "        \"semisupervised\", \"n_supervised_pairs\", \"batch-size-supervised\",\n",
    "        \"n_unsupervised_image\", \"n_unsupervised_text\", \"anchor_lam_x\",\n",
    "        \"anchor_lam_y\", \"alpha_semisupervised_sail\", \"alpha_semisupervised_ot\",\n",
    "        \"epsilon_sinkhorn_shared\", \"n_iters_sinkhorn_shared\",\n",
    "        \"epsilon_sinkhorn_anchor\", \"n_iters_sinkhorn_anchor\",\n",
    "        \"unsupervised_index_mode\",\n",
    "    ]\n",
    "\n",
    "    key_metrics = [\n",
    "        \"experiment_id\", \"coco_T2I R@1\", \"coco_T2I R@5\",\n",
    "        \"coco_I2T R@1\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\",\n",
    "    ]\n",
    "\n",
    "    # Extract Models and Datasets for ALL embedding columns\n",
    "    all_embedding_cols = [\n",
    "        \"supervised_image_embedding\", \"supervised_text_embedding\",\n",
    "        \"unsupervised_image_embedding\", \"unsupervised_text_embedding\",\n",
    "        \"val_image_embedding\", \"val_text_embedding\"\n",
    "    ]\n",
    "\n",
    "    dataset_cols = []\n",
    "\n",
    "    for col in all_embedding_cols:\n",
    "        if col in df.columns:\n",
    "            base_name = col.replace(\"_embedding\", \"\")\n",
    "            extracted = df[col].apply(extract_model_and_dataset)\n",
    "            \n",
    "            df[f\"{base_name}_model\"] = extracted.apply(lambda x: x[0])\n",
    "            df[f\"{base_name}\"] = extracted.apply(lambda x: x[1])\n",
    "            dataset_cols.append(base_name)\n",
    "            \n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Assert and merge image models\n",
    "    if \"supervised_image_model\" in df.columns and \"unsupervised_image_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_image_model\"] != df[\"unsupervised_image_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_image_model != unsupervised_image_model\")\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_image_model\", \"unsupervised_image_model\"]])\n",
    "        \n",
    "        df[\"image_model\"] = df[\"supervised_image_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_image_model\", \"unsupervised_image_model\"]\n",
    "        if \"val_image_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_image_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # Assert and merge text models\n",
    "    if \"supervised_text_model\" in df.columns and \"unsupervised_text_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_text_model\"] != df[\"unsupervised_text_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_text_model != unsupervised_text_model\")\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_text_model\", \"unsupervised_text_model\"]])\n",
    "\n",
    "        df[\"text_model\"] = df[\"supervised_text_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_text_model\", \"unsupervised_text_model\"]\n",
    "        if \"val_text_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_text_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    dataset_cols.sort()\n",
    "    model_cols = [\"image_model\", \"text_model\"]\n",
    "    \n",
    "    final_cols = key_metrics + model_cols + dataset_cols + param_columns\n",
    "    final_cols = [c for c in final_cols if c in df.columns]\n",
    "\n",
    "    df = df[final_cols]\n",
    "\n",
    "    # Sort by main metric\n",
    "    if \"coco_T2I R@1\" in df.columns:\n",
    "        df = df.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "\n",
    "    print(f\"\\nLoaded {len(df)} experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455d3094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>coco_T2I R@1</th>\n",
       "      <th>coco_T2I R@5</th>\n",
       "      <th>coco_I2T R@1</th>\n",
       "      <th>coco_I2T R@5</th>\n",
       "      <th>imagenet_top1</th>\n",
       "      <th>imagenet_top5</th>\n",
       "      <th>image_model</th>\n",
       "      <th>text_model</th>\n",
       "      <th>supervised_image</th>\n",
       "      <th>supervised_text</th>\n",
       "      <th>unsupervised_image</th>\n",
       "      <th>unsupervised_text</th>\n",
       "      <th>val_image</th>\n",
       "      <th>val_text</th>\n",
       "      <th>seed</th>\n",
       "      <th>logit_scale</th>\n",
       "      <th>logit_bias</th>\n",
       "      <th>semisupervised</th>\n",
       "      <th>n_supervised_pairs</th>\n",
       "      <th>n_unsupervised_image</th>\n",
       "      <th>n_unsupervised_text</th>\n",
       "      <th>anchor_lam_x</th>\n",
       "      <th>anchor_lam_y</th>\n",
       "      <th>alpha_semisupervised_sail</th>\n",
       "      <th>alpha_semisupervised_ot</th>\n",
       "      <th>epsilon_sinkhorn_shared</th>\n",
       "      <th>n_iters_sinkhorn_shared</th>\n",
       "      <th>epsilon_sinkhorn_anchor</th>\n",
       "      <th>n_iters_sinkhorn_anchor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-09_09-08-48_dinov2-large_NV-Embed-v2</td>\n",
       "      <td>0.22368</td>\n",
       "      <td>0.45472</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>39.762</td>\n",
       "      <td>69.972</td>\n",
       "      <td>dinov2-large</td>\n",
       "      <td>NV-Embed-v2</td>\n",
       "      <td>cc3m_concat.h5</td>\n",
       "      <td>cc3m_raw_caption.h5</td>\n",
       "      <td>cc3m_concat.h5</td>\n",
       "      <td>cc3m_raw_caption.h5</td>\n",
       "      <td>cc3m_concat_validation.h5</td>\n",
       "      <td>cc3m_raw_caption_validation.h5</td>\n",
       "      <td>42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-09_09-20-35_dinov2-large_NV-Embed-v2</td>\n",
       "      <td>0.21984</td>\n",
       "      <td>0.44496</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>40.146</td>\n",
       "      <td>71.144</td>\n",
       "      <td>dinov2-large</td>\n",
       "      <td>NV-Embed-v2</td>\n",
       "      <td>cc3m_concat.h5</td>\n",
       "      <td>cc3m_raw_caption.h5</td>\n",
       "      <td>cc12m_concat.h5</td>\n",
       "      <td>cc12m_raw_caption.h5</td>\n",
       "      <td>cc3m_concat_validation.h5</td>\n",
       "      <td>cc3m_raw_caption_validation.h5</td>\n",
       "      <td>42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-09_01-48-20_dinov2-large_NV-Embed-v2</td>\n",
       "      <td>0.01784</td>\n",
       "      <td>0.06108</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>3.250</td>\n",
       "      <td>10.090</td>\n",
       "      <td>dinov2-large</td>\n",
       "      <td>NV-Embed-v2</td>\n",
       "      <td>cc3m_concat.h5</td>\n",
       "      <td>cc3m_raw_caption.h5</td>\n",
       "      <td>cc3m_concat.h5</td>\n",
       "      <td>cc3m_raw_caption.h5</td>\n",
       "      <td>cc3m_concat_validation.h5</td>\n",
       "      <td>cc3m_raw_caption_validation.h5</td>\n",
       "      <td>42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  experiment_id  coco_T2I R@1  coco_T2I R@5  coco_I2T R@1  coco_I2T R@5  imagenet_top1  imagenet_top5   image_model   text_model supervised_image      supervised_text unsupervised_image     unsupervised_text                  val_image                        val_text seed logit_scale logit_bias semisupervised n_supervised_pairs n_unsupervised_image n_unsupervised_text anchor_lam_x anchor_lam_y alpha_semisupervised_sail alpha_semisupervised_ot epsilon_sinkhorn_shared n_iters_sinkhorn_shared epsilon_sinkhorn_anchor n_iters_sinkhorn_anchor\n",
       "1  2026-01-09_09-08-48_dinov2-large_NV-Embed-v2       0.22368       0.45472        0.2950        0.5382         39.762         69.972  dinov2-large  NV-Embed-v2   cc3m_concat.h5  cc3m_raw_caption.h5     cc3m_concat.h5   cc3m_raw_caption.h5  cc3m_concat_validation.h5  cc3m_raw_caption_validation.h5   42        20.0      -10.0           True              10000              1000000             1000000          0.1          0.1                       1.0                  0.0001                     0.1                      20                    0.01                     100\n",
       "2  2026-01-09_09-20-35_dinov2-large_NV-Embed-v2       0.21984       0.44496        0.2824        0.5230         40.146         71.144  dinov2-large  NV-Embed-v2   cc3m_concat.h5  cc3m_raw_caption.h5    cc12m_concat.h5  cc12m_raw_caption.h5  cc3m_concat_validation.h5  cc3m_raw_caption_validation.h5   42        20.0      -10.0           True              10000              1000000             1000000          0.1          0.1                       1.0                  0.0001                     0.1                      20                    0.01                     100\n",
       "0  2026-01-09_01-48-20_dinov2-large_NV-Embed-v2       0.01784       0.06108        0.0162        0.0650          3.250         10.090  dinov2-large  NV-Embed-v2   cc3m_concat.h5  cc3m_raw_caption.h5     cc3m_concat.h5   cc3m_raw_caption.h5  cc3m_concat_validation.h5  cc3m_raw_caption_validation.h5   42        20.0      -10.0           True              10000               100000              100000          0.1          0.1                       1.0                  0.0001                     0.1                      20                    0.01                     100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
