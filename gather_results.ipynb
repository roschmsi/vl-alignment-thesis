{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "OT_LOGS_DIR = Path(\"/lustre/groups/eml/projects/sroschmann/ot_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params(params_path):\n",
    "    params = {}\n",
    "    if not params_path.exists():\n",
    "        return params\n",
    "\n",
    "    try:\n",
    "        with open(params_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                if \":\" in line:\n",
    "                    key, val = line.split(\":\", 1)\n",
    "                elif \"=\" in line:\n",
    "                    key, val = line.split(\"=\", 1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                params[key.strip()] = val.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {params_path}: {e}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babf457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_flatten_metrics(json_path, prefix):\n",
    "    metrics = {}\n",
    "    if not json_path.exists():\n",
    "        return metrics\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            epoch_best = data.get(\"epoch_best\", {})\n",
    "\n",
    "            if isinstance(epoch_best, dict):\n",
    "                for key, value in epoch_best.items():\n",
    "                    col_name = f\"{prefix}_{key}\"\n",
    "                    metrics[col_name] = value\n",
    "            else:\n",
    "                raise ValueError(\"epoch_best is not a dictionary\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Issue parsing {json_path}: {e}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd952b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_dataframe(base_dir):\n",
    "    data_rows = []\n",
    "    print(f\"Scanning directory: {base_dir} ...\")\n",
    "\n",
    "    CUTOFF_TIMESTAMP = \"2026-01-15_21-36-57\"\n",
    "\n",
    "    for exp_dir in base_dir.iterdir():\n",
    "        if not exp_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        dir_timestamp = exp_dir.name[:19]\n",
    "        \n",
    "        if dir_timestamp < CUTOFF_TIMESTAMP:\n",
    "            continue\n",
    "\n",
    "        row = {\"experiment_id\": exp_dir.name, \"full_path\": str(exp_dir)}\n",
    "\n",
    "        params_path = exp_dir / \"params.txt\"\n",
    "        params = parse_params(params_path)\n",
    "        \n",
    "        if params.get(\"debugging\") == \"True\":\n",
    "            continue\n",
    "\n",
    "        row.update(params)\n",
    "\n",
    "        coco_path = exp_dir / \"results\" / \"COCO\" / \"alignment_probing.json\"\n",
    "        coco_metrics = load_and_flatten_metrics(coco_path, prefix=\"coco\")\n",
    "        row.update(coco_metrics)\n",
    "\n",
    "        imagenet_path = exp_dir / \"results\" / \"imagenetv1\" / \"alignment_probing.json\"\n",
    "        imagenet_metrics = load_and_flatten_metrics(imagenet_path, prefix=\"imagenet\")\n",
    "        row.update(imagenet_metrics)\n",
    "\n",
    "        data_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35524d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_and_dataset(path_str):\n",
    "    if not isinstance(path_str, str):\n",
    "        return None, None\n",
    "    \n",
    "    cleaned_str = path_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\").replace(\",\", \" \")\n",
    "    paths = cleaned_str.split()\n",
    "    \n",
    "    models = []\n",
    "    datasets = []\n",
    "    \n",
    "    for p in paths:\n",
    "        parts = p.strip(\"/\").split(\"/\")\n",
    "        if len(parts) >= 2:\n",
    "            models.append(parts[-2]) \n",
    "            datasets.append(parts[-1])\n",
    "            \n",
    "    if not models:\n",
    "        return None, None\n",
    "        \n",
    "    final_model = models[0]\n",
    "    final_dataset = \" + \".join(datasets)\n",
    "    \n",
    "    return final_model, final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = build_results_dataframe(OT_LOGS_DIR)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No experiments found.\")\n",
    "else:\n",
    "    # Define base columns (metrics + params)\n",
    "    param_columns = [\n",
    "        \"seed\", \"linear-type\", \"width-factor\", \"logit_scale\", \"logit_bias\",\n",
    "        \"semisupervised\", \"supervised\", \"n_supervised_pairs\", \"batch-size-supervised\",\n",
    "        \"n_unsupervised_image\", \"n_unsupervised_text\", \"anchor_lam_x\",\n",
    "        \"anchor_lam_y\", \"alpha_semisupervised_sail\", \"alpha_semisupervised_ot\", \"alpha_supervised_sail\", \"structure\",\n",
    "        \"epsilon_sinkhorn_shared\", \"n_iters_sinkhorn_shared\",\n",
    "        \"epsilon_sinkhorn_anchor\", \"n_iters_sinkhorn_anchor\",\n",
    "        \"unsupervised_index_mode\",\n",
    "    ]\n",
    "\n",
    "    key_metrics = [\n",
    "        \"experiment_id\", \"coco_T2I R@1\", \"coco_T2I R@5\",\n",
    "        \"coco_I2T R@1\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\",\n",
    "    ]\n",
    "\n",
    "    # Extract Models and Datasets for ALL embedding columns\n",
    "    all_embedding_cols = [\n",
    "        \"supervised_image_embedding\", \"supervised_text_embedding\",\n",
    "        \"unsupervised_image_embedding\", \"unsupervised_text_embedding\",\n",
    "        \"val_image_embedding\", \"val_text_embedding\"\n",
    "    ]\n",
    "\n",
    "    dataset_cols = []\n",
    "\n",
    "    for col in all_embedding_cols:\n",
    "        if col in df.columns:\n",
    "            base_name = col.replace(\"_embedding\", \"\")\n",
    "            extracted = df[col].apply(extract_model_and_dataset)\n",
    "            \n",
    "            df[f\"{base_name}_model\"] = extracted.apply(lambda x: x[0])\n",
    "            df[f\"{base_name}\"] = extracted.apply(lambda x: x[1])\n",
    "            dataset_cols.append(base_name)\n",
    "            \n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Assert and merge image models\n",
    "    if \"supervised_image_model\" in df.columns and \"unsupervised_image_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_image_model\"] != df[\"unsupervised_image_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_image_model != unsupervised_image_model\")\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_image_model\", \"unsupervised_image_model\"]])\n",
    "        \n",
    "        df[\"image_model\"] = df[\"supervised_image_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_image_model\", \"unsupervised_image_model\"]\n",
    "        if \"val_image_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_image_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # Assert and merge text models\n",
    "    if \"supervised_text_model\" in df.columns and \"unsupervised_text_model\" in df.columns:\n",
    "        mismatches = df[df[\"supervised_text_model\"] != df[\"unsupervised_text_model\"]]\n",
    "        if not mismatches.empty:\n",
    "            print(f\"\\n[WARNING] Found {len(mismatches)} experiments where supervised_text_model != unsupervised_text_model\")\n",
    "            print(mismatches['experiment_id'])\n",
    "            print(mismatches[[\"experiment_id\", \"supervised_text_model\", \"unsupervised_text_model\"]])\n",
    "\n",
    "        df[\"text_model\"] = df[\"supervised_text_model\"]\n",
    "        \n",
    "        cols_to_drop = [\"supervised_text_model\", \"unsupervised_text_model\"]\n",
    "        if \"val_text_model\" in df.columns:\n",
    "            cols_to_drop.append(\"val_text_model\")\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    dataset_cols.sort()\n",
    "    model_cols = [\"image_model\", \"text_model\"]\n",
    "    \n",
    "    final_cols = key_metrics + model_cols + dataset_cols + param_columns\n",
    "    final_cols = [c for c in final_cols if c in df.columns]\n",
    "\n",
    "    df = df[final_cols]\n",
    "\n",
    "    # Sort by main metric\n",
    "    if \"coco_T2I R@1\" in df.columns:\n",
    "        df = df.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "\n",
    "    print(f\"\\nLoaded {len(df)} experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca18df",
   "metadata": {},
   "source": [
    "### Number of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_supervised_pairs = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_n_supervised_pairs = df_n_supervised_pairs.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_n_supervised_pairs[[\"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"n_supervised_pairs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_siglip_supervised = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"supervised\"]) & \n",
    "   (df[\"alpha_supervised_sail\"] == \"1.0\")]\n",
    "df_cc3m_siglip_supervised = df_cc3m_siglip_supervised.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_siglip_supervised[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"n_supervised_pairs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a589a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "float_cols = ['coco_T2I R@1', 'coco_I2T R@1', 'coco_T2I R@5', 'coco_I2T R@5', 'imagenet_top1', 'imagenet_top5']\n",
    "int_cols = ['n_supervised_pairs']\n",
    "\n",
    "# Convert SOTAlign\n",
    "for col in float_cols:\n",
    "    df_n_supervised_pairs[col] = pd.to_numeric(df_n_supervised_pairs[col], errors='coerce')\n",
    "for col in int_cols:\n",
    "    df_n_supervised_pairs[col] = pd.to_numeric(df_n_supervised_pairs[col], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert Baseline\n",
    "for col in float_cols:\n",
    "    df_cc3m_siglip_supervised[col] = pd.to_numeric(df_cc3m_siglip_supervised[col], errors='coerce')\n",
    "for col in int_cols:\n",
    "    df_cc3m_siglip_supervised[col] = pd.to_numeric(df_cc3m_siglip_supervised[col], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "df_sotalign_sorted = df_n_supervised_pairs.sort_values(by='n_supervised_pairs')\n",
    "df_baseline_sorted = df_cc3m_siglip_supervised.sort_values(by='n_supervised_pairs')\n",
    "\n",
    "df_sotalign_sorted = df_sotalign_sorted[df_sotalign_sorted['n_supervised_pairs'] <= 50000]\n",
    "df_baseline_sorted = df_baseline_sorted[df_baseline_sorted['n_supervised_pairs'] <= 50000]\n",
    "\n",
    "def plot_metric_comparison(metric_col, title, ylabel, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.plot(df_sotalign_sorted['n_supervised_pairs'], df_sotalign_sorted[metric_col],\n",
    "             marker='o', linestyle='-', color='b', label='SOTAlign (Ours)', linewidth=2)\n",
    "\n",
    "    plt.plot(df_baseline_sorted['n_supervised_pairs'], df_baseline_sorted[metric_col],\n",
    "             marker='^', linestyle='--', color='r', label='Supervised SigLIP (SAIL)', linewidth=2)\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Number of pairs')\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_metric_comparison(\n",
    "    'coco_T2I R@1', \n",
    "    'COCO Text-to-Image Retrieval R@1', \n",
    "    'T2I R@1', \n",
    "    'plot_coco_t2i_r1.png'\n",
    ")\n",
    "\n",
    "plot_metric_comparison(\n",
    "    'coco_I2T R@1', \n",
    "    'COCO Image-to-Text Retrieval R@1', \n",
    "    'I2T R@1', \n",
    "    'plot_coco_i2t_r1.png'\n",
    ")\n",
    "\n",
    "plot_metric_comparison(\n",
    "    'imagenet_top1', \n",
    "    'ImageNet Top 1 Accuracy', \n",
    "    'Top-1 Accuracy', \n",
    "    'plot_imagenet_top1.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07da1f7",
   "metadata": {},
   "source": [
    "### Number of unpaired samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_unsupervised_samples = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") & \n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_n_unsupervised_samples = df_n_unsupervised_samples.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_n_unsupervised_samples[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"n_unsupervised_image\", \"n_unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# Set global font size\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Data Preparation\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Unsupervised Data\n",
    "data_unsupervised = \"\"\"\n",
    "experiment_id\tcoco_T2I R@1\tcoco_I2T R@1\tcoco_T2I R@5\tcoco_I2T R@5\timagenet_top1\timagenet_top5\timage_model\ttext_model\tn_unsupervised_image\tn_unsupervised_text\n",
    "17\t0.22612\t0.2928\t0.45540\t0.5424\t40.064\t70.828\tdinov2-large\tNV-Embed-v2\t100000\t100000\n",
    "4\t0.22260\t0.2868\t0.44948\t0.5232\t39.026\t68.772\tdinov2-large\tNV-Embed-v2\t1000000\t1000000\n",
    "2\t0.19952\t0.2562\t0.42232\t0.4930\t34.858\t65.064\tdinov2-large\tNV-Embed-v2\t10000\t10000\n",
    "\"\"\"\n",
    "df_unsup = pd.read_csv(io.StringIO(data_unsupervised), sep='\\t')\n",
    "\n",
    "# Baseline Data (0 samples)\n",
    "baseline_data = {\n",
    "    \"coco_T2I R@1\": [0.18924],\n",
    "    \"coco_I2T R@1\": [0.2352],\n",
    "    \"imagenet_top1\": [32.714],\n",
    "    \"n_unsupervised_image\": [0]\n",
    "}\n",
    "df_baseline = pd.DataFrame(baseline_data)\n",
    "\n",
    "# Combine and Sort\n",
    "# We concatenate them to treat them as a single series\n",
    "cols_to_use = [\"n_unsupervised_image\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"imagenet_top1\"]\n",
    "df_combined = pd.concat([df_baseline[cols_to_use], df_unsup[cols_to_use]], ignore_index=True)\n",
    "df_combined = df_combined.sort_values(by=\"n_unsupervised_image\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Plotting Logic\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def plot_equal_spacing(metric_col, title, ylabel, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create artificial indices: 0, 1, 2, 3...\n",
    "    x_indices = np.arange(len(df_combined))\n",
    "    y_values = df_combined[metric_col].values\n",
    "    \n",
    "    # Define custom labels\n",
    "    def format_label(n):\n",
    "        if n == 0: return \"0\"\n",
    "        if n >= 1000000: return f\"{int(n/1000000)}M\"\n",
    "        if n >= 1000: return f\"{int(n/1000)}k\"\n",
    "        return str(n)\n",
    "        \n",
    "    x_labels = [format_label(n) for n in df_combined[\"n_unsupervised_image\"]]\n",
    "\n",
    "    # 1. Plot the Connecting Line (No label, just visual)\n",
    "    plt.plot(x_indices, y_values, color='blue', linestyle='-', linewidth=2, zorder=1)\n",
    "    \n",
    "    # 2. Plot the Markers (SWAPPED ORDER)\n",
    "    \n",
    "    # FIRST: Plot SOTAlign (Blue Circles) so it appears top in legend\n",
    "    plt.scatter(x_indices[1:], y_values[1:], color='blue', marker='o', s=100, zorder=2, label='SOTAlign (Ours)')\n",
    "\n",
    "    # SECOND: Plot Baseline (Red Triangle) so it appears bottom in legend\n",
    "    plt.scatter(x_indices[0], y_values[0], color='red', marker='^', s=150, zorder=2, label='Supervised SigLIP (SAIL)')\n",
    "\n",
    "    # 3. Configure X-Axis\n",
    "    plt.xticks(x_indices, x_labels)\n",
    "    plt.xlabel('Number of unsupervised samples')\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.title(title)\n",
    "    plt.legend()  # Now renders SOTAlign first\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Generate Plots\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "plot_equal_spacing('coco_T2I R@1', 'COCO Text-to-Image Retrieval R@1', 'T2I R@1', 'equal_coco_t2i.png')\n",
    "plot_equal_spacing('coco_I2T R@1', 'COCO Image-to-Text Retrieval R@1', 'I2T R@1', 'equal_coco_i2t.png')\n",
    "plot_equal_spacing('imagenet_top1', 'ImageNet Top 1 Accuracy', 'Top-1 Accuracy', 'equal_imagenet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4099588",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Iterate over the dataframe rows\n",
    "for index, row in df_n_unsupervised_samples.iterrows():\n",
    "    # Use 'n_unsupervised_image' as the anchor key (10k, 100k, 1M)\n",
    "    # converting to int just in case it's a string or float\n",
    "    n_samples = int(row[\"n_unsupervised_image\"])\n",
    "    \n",
    "    # Build the nested structure\n",
    "    results[n_samples] = {\n",
    "        \"ours\": {\n",
    "            # Convert fractional COCO scores (e.g., 0.226) to percentages (22.6)\n",
    "            \"t2i_r1\": row[\"coco_T2I R@1\"] * 100,\n",
    "            \"i2t_r1\": row[\"coco_I2T R@1\"] * 100,\n",
    "            \n",
    "            # ImageNet is already in percentage format in your table\n",
    "            \"cls_acc\": row[\"imagenet_top1\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SigLIP semisupervised baseline as reference for 0 unsupervised samples\n",
    "df_cc3m_siglip_semisupervised = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") &\n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0\")]\n",
    "\n",
    "df_cc3m_siglip_semisupervised = df_cc3m_siglip_semisupervised.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_siglip_semisupervised[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_siglip_semisupervised = df_cc3m_siglip_semisupervised.dropna(subset=[\"coco_T2I R@1\", \"imagenet_top1\"])\n",
    "\n",
    "# 2. Add the first valid row to results for 0 unsupervised samples\n",
    "if not df_cc3m_siglip_semisupervised.empty:\n",
    "    row_zero = df_cc3m_siglip_semisupervised.iloc[0]\n",
    "    \n",
    "    results[0] = {\n",
    "        \"ours\": {\n",
    "            # Converting fractional COCO scores to percentages as before\n",
    "            # Note: Keeping your mapping of R@5 data to 'r1' keys to match your previous loop\n",
    "            \"t2i_r1\": row_zero[\"coco_T2I R@1\"] * 100, \n",
    "            \"i2t_r1\": row_zero[\"coco_I2T R@1\"] * 100,\n",
    "            \n",
    "            # ImageNet is already in percentage\n",
    "            \"cls_acc\": row_zero[\"imagenet_top1\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75872dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting.plot_unpaired_samples_vs_performance import plot_num_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e01af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot_num_unpaired(\n",
    "    results,\n",
    "    baseline=None,\n",
    "    metric_key=\"t2i_r1\",\n",
    "    title=\"COCO T2I Retrieval\",\n",
    "    ylabel=\"R@1\",\n",
    "    filename=\"t2i_r1_num_unpaired_samples.png\",\n",
    ")\n",
    "p2 = plot_num_unpaired(\n",
    "    results,\n",
    "    baseline=None,\n",
    "    metric_key=\"i2t_r1\",\n",
    "    title=\"COCO I2T Retrieval\",\n",
    "    ylabel=\"R@1\",\n",
    "    filename=\"i2t_r1_num_unpaired_samples.png\",\n",
    ")\n",
    "p3 = plot_num_unpaired(\n",
    "    results,\n",
    "    baseline=None,\n",
    "    metric_key=\"cls_acc\",\n",
    "    title=\"ImageNet Classification\",\n",
    "    ylabel=\"Accuracy (%)\",\n",
    "    filename=\"cls_acc_num_unpaired_samples.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae208cc",
   "metadata": {},
   "source": [
    "### Raw vs synthetic captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_raw_synthetic = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   ((df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") | (df[\"supervised_text\"] == \"cc3m_shortSV_captions.h5\")) & \n",
    "   ((df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") | (df[\"unsupervised_text\"] == \"cc3m_shortSV_captions.h5\")) & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_cc3m_raw_synthetic = df_cc3m_raw_synthetic.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "# \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top5\"\n",
    "df_cc3m_raw_synthetic[[\"coco_T2I R@1\", \"coco_I2T R@1\", \"imagenet_top1\", \"image_model\", \"text_model\", \"supervised_text\", \"unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec5612",
   "metadata": {},
   "source": [
    "### CC3M anchors and CC12M unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb46c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_cc12m = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   ((df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") | (df[\"unsupervised_text\"] == \"cc12m_raw_caption.h5\")) & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   ((df[\"unsupervised_image\"] == \"cc3m_concat.h5\") | (df[\"unsupervised_image\"] == \"cc12m_concat.h5\")) &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_cc3m_cc12m = df_cc3m_cc12m.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_cc12m[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_image\", \"unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6f12a",
   "metadata": {},
   "source": [
    "### Unsupervised ImageNet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46535945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_imagenet = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   ((df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") | (df[\"unsupervised_text\"] == \"cc12m_raw_caption.h5\")) & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"imagenet1k_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_cc3m_imagenet = df_cc3m_imagenet.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_imagenet[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_image\", \"unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276443aa",
   "metadata": {},
   "source": [
    "### Unsupervised COCO images and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1dc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_coco = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   ((df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") | (df[\"unsupervised_text\"] == \"cc12m_raw_caption.h5\")) & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"coco_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_cc3m_coco = df_cc3m_coco.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_coco[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_image\", \"unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_coco = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"coco_raw_caption_idx=0.h5 + coco_raw_caption_idx=1.h5 + coco_raw_caption_idx=2.h5 + coco_raw_caption_idx=3.h5 + coco_raw_caption_idx=4.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") & \n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")]\n",
    "df_cc3m_coco = df_cc3m_coco.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_coco[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_image\", \"unsupervised_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85d1fd",
   "metadata": {},
   "source": [
    "### Supervised SigLIP baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_siglip_supervised = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"supervised\"]) & \n",
    "   (df[\"alpha_supervised_sail\"] == \"1.0\")]\n",
    "df_cc3m_siglip_supervised = df_cc3m_siglip_supervised.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_siglip_supervised[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed2fff",
   "metadata": {},
   "source": [
    "### Semisupervised SigLIP baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_siglip_semisupervised = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") &\n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0\")]\n",
    "\n",
    "df_cc3m_siglip_semisupervised = df_cc3m_siglip_semisupervised.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_siglip_semisupervised[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"coco_T2I R@5\", \"coco_I2T R@5\", \"imagenet_top1\", \"imagenet_top5\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f47621",
   "metadata": {},
   "source": [
    "### STRUCTURE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"structure\"] = df[\"structure\"].fillna(False).astype(bool)\n",
    "df_cc3m_structure = df[(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & \n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) & \n",
    "   (df[\"structure\"])\n",
    "]\n",
    "\n",
    "df_cc3m_structure = df_cc3m_structure.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_structure[[\"experiment_id\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"imagenet_top1\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\", \"structure\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c28104",
   "metadata": {},
   "source": [
    "### Model ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"image_model\"] == \"dinov2-large\") & \n",
    "   (df[\"text_model\"] == \"NV-Embed-v2\") & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_models = df[\n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) &\n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") &\n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")\n",
    "]\n",
    "\n",
    "df_cc3m_models = df_cc3m_models.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_models[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64dccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc3m_models = df[\n",
    "   (df[\"supervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"unsupervised_text\"] == \"cc3m_raw_caption.h5\") & \n",
    "   (df[\"supervised_image\"] == \"cc3m_concat.h5\") & \n",
    "   (df[\"unsupervised_image\"] == \"cc3m_concat.h5\") &\n",
    "   (df[\"n_supervised_pairs\"] == \"10000\") &\n",
    "   (df[\"n_unsupervised_image\"] == \"1000000\") & \n",
    "   (df[\"n_unsupervised_text\"] == \"1000000\") &\n",
    "   (df[\"semisupervised\"]) &\n",
    "   (df[\"alpha_semisupervised_sail\"] == \"1.0\") &\n",
    "   (df[\"alpha_semisupervised_ot\"] == \"0.0001\")\n",
    "]\n",
    "\n",
    "df_cc3m_models = df_cc3m_models.sort_values(by=\"coco_T2I R@1\", ascending=False)\n",
    "df_cc3m_models[[\"imagenet_top1\", \"coco_T2I R@1\", \"coco_I2T R@1\", \"image_model\", \"text_model\", \"unsupervised_text\", \"unsupervised_image\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
